#1 create table in postgres

CREATE TABLE users
(
    id         SERIAL PRIMARY KEY,
    username   VARCHAR(50)  NOT NULL,
    email      VARCHAR(100) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

#2 then add some data
DO
$$
BEGIN
FOR i IN 1..20 LOOP
        INSERT INTO users (username, email, created_at)
        VALUES (
            CONCAT('user', i),
            CONCAT('user', i, '@example.com'),
            NOW() - (INTERVAL '1 day' * (RANDOM() * 365)::INT)
        );
END LOOP;
END $$;

#3 create debezium topic for kafka
"debezium-postgresql-connector.json" file inside this:
{
    "name": "pg-users-connector",
    "config": {
      "connector.class": "io.debezium.connector.postgresql.PostgresConnector",
      "database.dbname": "postgres",
      "database.history.kafka.bootstrap.servers": "kafka:9092",
      "database.history.kafka.topic": "schema-changes.users",
      "database.history.skip.unparseable.ddl": "true",
      "database.hostname": "postgres",
      "database.password": "1",
      "database.port": "5432",
      "database.server.name": "postgres",
      "database.user": "postgres",
      "key.converter": "io.confluent.connect.avro.AvroConverter",
      "key.converter.schema.registry.url": "http://schema-registry:8081",
      "name": "pg-users-connector",
      "plugin.name": "pgoutput",
      "snapshot.mode": "initial",
      "table.include.list": "public.users",
      "tasks.max": "1",
      "topic.creation.default.cleanup.policy": "delete",
      "topic.creation.default.partitions": "1",
      "topic.creation.default.replication.factor": "1",
      "topic.creation.default.retention.ms": "604800000",
      "topic.creation.enable": "true",
      "topic.prefix": "pg",
      "transforms": "unwrap",
      "transforms.unwrap.type": "io.debezium.transforms.ExtractNewRecordState",
      "value.converter": "io.confluent.connect.avro.AvroConverter",
      "value.converter.schema.registry.url": "http://schema-registry:8081"
}
}

run command:
    curl -i -X POST -H "Accept:application/json" -H "Content-Type:application/json" http://localhost:8083/connectors/ -d @debezium-postgresql-connector.json

#4  clickhouse actions

    #4.1 create database
    create database postgres;

    #4.2 create table
    CREATE TABLE postgres.users
    (
        id         UInt32,
        username   String,
        email      String,
        created_at DateTime DEFAULT now()
    ) ENGINE = ReplacingMergeTree
          ORDER BY (id)
          SETTINGS index_granularity = 8192;
    #4.3 create kafka database
    create database kafka_postgres;

    #4.4 create kafka engine table for only read
    CREATE TABLE kafka_postgres.users
    (
        id         UInt32,
        username   String,
        email      String,
        created_at UInt64
    ) ENGINE = Kafka
          SETTINGS kafka_broker_list = 'broker:29092',
              kafka_topic_list = 'pg.public.users',
              kafka_group_name = 'clickhouse_users',
              kafka_format = 'AvroConfluent',
              format_avro_schema_registry_url = 'http://schema-registry:8081';


    #4.5 create  view for auto write to main table
    CREATE MATERIALIZED VIEW kafka_postgres.consumer_users
                TO postgres.users
                (
                 id UInt32,
                 username String,
                 email String,
                 created_at DateTime
                    )
    AS
    SELECT id,
           username,
           email,
           toDateTime(created_at / 1000000) AS created_at
    FROM kafka_postgres.users;

